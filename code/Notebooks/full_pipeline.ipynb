{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1706ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hotson/kaggle_work/recodai-luc-scientific-image-forgery-detection/code\n"
     ]
    }
   ],
   "source": [
    "%cd /home/hotson/kaggle_work/recodai-luc-scientific-image-forgery-detection/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984ace4",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from transformers import AutoProcessor\n",
    "from torchvision import transforms\n",
    "\n",
    "from dinov2_uperhead import DinoV2_UPerNet\n",
    "from dinov2_unet import DinoV2UNet\n",
    "from utils import rle_encode, evaluate_single_image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class Config:\n",
    "    yolo_img_size = 1024\n",
    "    yolo_conf = 0.25\n",
    "    yolo_iou = 0.6\n",
    "\n",
    "margin = 20\n",
    "img_size = 532\n",
    "\n",
    "area_thres = 400\n",
    "mean_in_thres = 0.55\n",
    "min_cc_area = 50\n",
    "\n",
    "# area_thres = 600\n",
    "# mean_in_thres = 0.65\n",
    "# min_cc_area = 200\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Loading detector\n",
    "detect_model = YOLO(\"../runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Loading segmentation model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state = torch.load(\"../exps/20260115_182834/vit_base_patch14_dinov2.lvd142m_fold0.pt\", map_location=device)\n",
    "# state = torch.load(\"../exps/20260110_193809/vit_base_patch14_dinov2.lvd142m_fold0.pt\", map_location=device)\n",
    "model_state = state[\"model_state\"]\n",
    "seg_model = DinoV2_UPerNet(dinov2_id=\"facebook/dinov2-base\", num_classes=1).to(device)\n",
    "# seg_model = DinoV2UNet(dinov2_id=\"facebook/dinov2-base\", out_classes=1).to(device)\n",
    "seg_model.load_state_dict(model_state)\n",
    "seg_model.eval()\n",
    "\n",
    "supplemental_images = Path(\"../supplemental_images\")\n",
    "\n",
    "def apply_clahe(image: Image.Image) -> Image.Image:\n",
    "    img_np = np.array(image)\n",
    "    lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l2 = clahe.apply(l)\n",
    "    lab2 = cv2.merge((l2, a, b))\n",
    "    enhanced = cv2.cvtColor(lab2, cv2.COLOR_LAB2RGB)\n",
    "    return Image.fromarray(enhanced)\n",
    "\n",
    "\n",
    "def enhanced_adaptive_mask(prob: np.ndarray, alpha_grad=0.45):\n",
    "    prob = np.asarray(prob, dtype=np.float32)\n",
    "    if prob.ndim == 3:\n",
    "        prob = prob[..., 0]\n",
    "\n",
    "    gx = cv2.Sobel(prob, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(prob, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "    grad_norm = grad_mag / (grad_mag.max() + 1e-6)\n",
    "\n",
    "    enhanced = (1 - alpha_grad) * prob + alpha_grad * grad_norm\n",
    "    enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "\n",
    "    thr = float(np.mean(enhanced) + 0.1 * np.std(enhanced))\n",
    "    mask = (enhanced > thr).astype(np.uint8)\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    return mask, thr\n",
    "\n",
    "\n",
    "def finalize_mask(prob: np.ndarray, orig_size_wh: tuple[int, int]):\n",
    "    mask, thr = enhanced_adaptive_mask(prob)\n",
    "    w, h = orig_size_wh\n",
    "    mask = cv2.resize(mask, (int(w), int(h)), interpolation=cv2.INTER_NEAREST)\n",
    "    return mask, thr\n",
    "\n",
    "\n",
    "def remove_small_components(mask01: np.ndarray, min_area: int) -> np.ndarray:\n",
    "    if min_area is None or min_area <= 0:\n",
    "        return (mask01 > 0).astype(np.uint8)\n",
    "\n",
    "    m = (mask01 > 0).astype(np.uint8)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(m, connectivity=8)\n",
    "\n",
    "    out = np.zeros_like(m, dtype=np.uint8)\n",
    "    for lab in range(1, num_labels):\n",
    "        if stats[lab, cv2.CC_STAT_AREA] >= min_area:\n",
    "            out[labels == lab] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "def preprocess(image: Image.Image, base_model_preprocessor, img_size: int = 532):\n",
    "    image = apply_clahe(image)\n",
    "    image = transforms.functional.resize(image, (img_size, img_size))\n",
    "    processed = base_model_preprocessor(\n",
    "        images=image,\n",
    "        return_tensors=\"pt\",\n",
    "        do_resize=False,\n",
    "        do_center_crop=False,\n",
    "        do_normalize=True,\n",
    "        do_rescale=True,\n",
    "    )\n",
    "    return processed[\"pixel_values\"].squeeze(0)  # [C,H,W]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_seg_mask_raw(image: Image.Image, H: int, W: int):\n",
    "    \"\"\"\n",
    "    Returns raw predicted binary mask (after finalize + CC),\n",
    "    plus prob maps for viz/aggregation.\n",
    "\n",
    "    Returns:\n",
    "      pred_bin   : (H,W) uint8 {0,1}\n",
    "      prob_full  : (H,W) float32 in [0,1]\n",
    "      prob_small : (S,S) float32 in [0,1]  (model-res, i.e., img_size x img_size)\n",
    "    \"\"\"\n",
    "    image = apply_clahe(image)\n",
    "\n",
    "    x = img_transform(image)          # (3,S,S)\n",
    "    x = x.unsqueeze(0).to(device)     # (1,3,S,S)\n",
    "\n",
    "    out = seg_model(x)\n",
    "    logits = out if torch.is_tensor(out) else out[0]\n",
    "\n",
    "    prob_small = torch.sigmoid(logits)[0, 0].detach().cpu().numpy().astype(np.float32)  # (S,S)\n",
    "\n",
    "    # binarize at orig-res using your existing finalize_mask()\n",
    "    mask_full, _ = finalize_mask(prob_small, (W, H))  # (H,W) uint8-ish\n",
    "    pred_bin = (mask_full > 0).astype(np.uint8)\n",
    "\n",
    "    # IMPORTANT: for crops, DO NOT use the same big CC threshold here.\n",
    "    # We'll do CC + gating once globally after merging.\n",
    "    prob_full = cv2.resize(prob_small, (W, H), interpolation=cv2.INTER_LINEAR).astype(np.float32)\n",
    "\n",
    "    return pred_bin, prob_full, prob_small\n",
    "\n",
    "\n",
    "def load_gt_mask_from_image_path(image_path: str, w: int, h: int) -> np.ndarray:\n",
    "    mask_path = (\n",
    "        image_path\n",
    "        .replace(\"train_images\", \"train_masks\")\n",
    "        .replace(\"supplemental_images\", \"supplemental_masks\")\n",
    "        .replace(\"/forged\", \"\")\n",
    "        .replace(\".png\", \".npy\")\n",
    "    )\n",
    "    if not Path(mask_path).exists():\n",
    "        return np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "    arr = np.load(mask_path, allow_pickle=True)\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr.max(axis=0)\n",
    "    gt_mask = (arr > 0).astype(np.uint8)\n",
    "    if gt_mask.shape[:2] != (h, w):\n",
    "        gt_mask = cv2.resize(gt_mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "    return gt_mask\n",
    "\n",
    "def apply_overlay_rgb(img_rgb: np.ndarray, mask01: np.ndarray, color=(255, 0, 0), alpha=0.45):\n",
    "    \"\"\"\n",
    "    img_rgb: (H,W,3) uint8\n",
    "    mask01: (H,W) {0,1} or {0,255}\n",
    "    \"\"\"\n",
    "    out = img_rgb.copy()\n",
    "    m = (mask01 > 0)\n",
    "    if m.any():\n",
    "        col = np.array(color, dtype=np.float32)\n",
    "        out[m] = (alpha * col + (1 - alpha) * out[m].astype(np.float32)).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def draw_yolo_boxes(img_rgb: np.ndarray, boxes_xyxy: np.ndarray, color=(255, 0, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Draws xyxy boxes on RGB image. Uses cv2 (expects BGR), so we convert back/forth.\n",
    "    boxes_xyxy: (N,4) float or int in xyxy.\n",
    "    \"\"\"\n",
    "    if boxes_xyxy is None or len(boxes_xyxy) == 0:\n",
    "        return img_rgb\n",
    "\n",
    "    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "    for b in boxes_xyxy:\n",
    "        x1, y1, x2, y2 = [int(round(v)) for v in b.tolist()]\n",
    "        cv2.rectangle(img_bgr, (x1, y1), (x2, y2), color[::-1], thickness)  # reverse to BGR\n",
    "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def overlay_heatmap_on_rgb(img_rgb: np.ndarray, heat01: np.ndarray, alpha=0.45):\n",
    "    \"\"\"\n",
    "    img_rgb: (H,W,3) uint8\n",
    "    heat01:  (H,W) float in [0,1]\n",
    "    \"\"\"\n",
    "    h = np.clip(heat01, 0.0, 1.0)\n",
    "    h255 = (h * 255).astype(np.uint8)\n",
    "    heat_bgr = cv2.applyColorMap(h255, cv2.COLORMAP_JET)\n",
    "    heat_rgb = cv2.cvtColor(heat_bgr, cv2.COLOR_BGR2RGB)\n",
    "    out = (alpha * heat_rgb.astype(np.float32) + (1 - alpha) * img_rgb.astype(np.float32)).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "def normalize01(x: np.ndarray, eps=1e-6):\n",
    "    x = x.astype(np.float32)\n",
    "    mn, mx = float(x.min()), float(x.max())\n",
    "    if mx - mn < eps:\n",
    "        return np.zeros_like(x, dtype=np.float32)\n",
    "    return (x - mn) / (mx - mn)\n",
    "\n",
    "\n",
    "break_loop = 3\n",
    "\n",
    "scores = []\n",
    "for img_path in tqdm(sorted(supplemental_images.glob(\"*.png\")), desc=\"Inference\"):\n",
    "    case_id = img_path.stem\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    W, H = image.size\n",
    "\n",
    "    predicted_mask = np.zeros((H, W), dtype=np.uint8)\n",
    "    prob_accum = np.zeros((H, W), dtype=np.float32)\n",
    "    prob_count = np.zeros((H, W), dtype=np.float32)\n",
    "\n",
    "    preds = detect_model.predict(\n",
    "        source=str(img_path),\n",
    "        conf=Config.yolo_conf,\n",
    "        iou=Config.yolo_iou,\n",
    "        imgsz=Config.yolo_img_size,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    boxes = preds[0].boxes\n",
    "    crops = []\n",
    "\n",
    "    is_authentic = True\n",
    "\n",
    "    if boxes is None or len(boxes) <= 1:\n",
    "        # whole-image segmentation\n",
    "        pred_bin, prob_full, prob_small = get_seg_mask_raw(image, H=H, W=W)\n",
    "        predicted_mask = np.maximum(predicted_mask, pred_bin)\n",
    "\n",
    "        prob_accum += prob_full\n",
    "        prob_count += 1.0\n",
    "\n",
    "        # keep for viz\n",
    "        boxes_xyxy = None\n",
    "    else:\n",
    "        boxes_xyxy = boxes.xyxy.cpu().numpy()  # for drawing\n",
    "\n",
    "        for bbox in boxes_xyxy:\n",
    "            x1, y1, x2, y2 = bbox.tolist()\n",
    "\n",
    "            # ints + clamp\n",
    "            x1 = int(max(0, x1)); y1 = int(max(0, y1))\n",
    "            x2 = int(min(W, x2)); y2 = int(min(H, y2))\n",
    "\n",
    "            # apply margin safely\n",
    "            x1m = int(min(W, x1 + margin))\n",
    "            y1m = int(min(H, y1 + margin))\n",
    "            x2m = int(max(0, x2 - margin))\n",
    "            y2m = int(max(0, y2 - margin))\n",
    "\n",
    "            if x2m <= x1m or y2m <= y1m:\n",
    "                continue\n",
    "\n",
    "            crop = image.crop((x1m, y1m, x2m, y2m))\n",
    "            cw, ch = crop.size\n",
    "            crops.append(crop)\n",
    "\n",
    "            pred_bin, crop_prob_full, crop_prob_small = get_seg_mask_raw(crop, H=ch, W=cw)\n",
    "\n",
    "            predicted_mask[y1m:y2m, x1m:x2m] = np.maximum(\n",
    "                predicted_mask[y1m:y2m, x1m:x2m],\n",
    "                pred_bin\n",
    "            )\n",
    "\n",
    "            prob_accum[y1m:y2m, x1m:x2m] += crop_prob_full\n",
    "            prob_count[y1m:y2m, x1m:x2m] += 1.0\n",
    "            \n",
    "    # average probability where we have coverage\n",
    "    prob_vis = prob_accum / np.maximum(prob_count, 1e-6)\n",
    "\n",
    "    # CC filter ONCE (global)\n",
    "    predicted_mask = remove_small_components(predicted_mask, min_cc_area)\n",
    "\n",
    "    area = int(predicted_mask.sum())\n",
    "    if area > 0:\n",
    "        mean_inside = float(prob_vis[predicted_mask == 1].mean())\n",
    "    else:\n",
    "        mean_inside = 0.0\n",
    "\n",
    "    is_forged = (area >= area_thres) and (mean_inside >= mean_in_thres)\n",
    "\n",
    "    if not is_forged:\n",
    "        predicted_mask[:] = 0\n",
    "\n",
    "    # Evaluate vs GT (supplemental has masks)\n",
    "    gt_mask = load_gt_mask_from_image_path(str(img_path), w=W, h=H)\n",
    "\n",
    "    label_rles = rle_encode([gt_mask])\n",
    "    prediction_rles = rle_encode([predicted_mask])\n",
    "\n",
    "    score = evaluate_single_image(\n",
    "        label_rles=label_rles,\n",
    "        prediction_rles=prediction_rles,\n",
    "        shape_str=json.dumps([int(H), int(W)])\n",
    "    )\n",
    "    scores.append(score)\n",
    "\n",
    "    # ----- visualize -----\n",
    "    img_np = np.array(image)  # RGB uint8\n",
    "\n",
    "    # if boxes_xyxy wasn't set (whole-image path), set None safely\n",
    "    if \"boxes_xyxy\" not in locals():\n",
    "        boxes_xyxy = None\n",
    "\n",
    "    img_with_boxes = draw_yolo_boxes(img_np, boxes_xyxy, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "    pred_overlay = apply_overlay_rgb(img_np, predicted_mask, color=(255, 0, 0), alpha=0.45)  # red\n",
    "    gt_overlay   = apply_overlay_rgb(img_np, gt_mask,        color=(0, 255, 0), alpha=0.45)  # green\n",
    "\n",
    "    both_overlay = img_np.copy()\n",
    "    both_overlay = apply_overlay_rgb(both_overlay, gt_mask,        color=(0, 255, 0), alpha=0.35)\n",
    "    both_overlay = apply_overlay_rgb(both_overlay, predicted_mask, color=(255, 0, 0), alpha=0.35)\n",
    "    both_overlay = draw_yolo_boxes(both_overlay, boxes_xyxy, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "    # heatmap + overlay\n",
    "    heat = np.clip(prob_vis, 0.0, 1.0)\n",
    "    heat_overlay = overlay_heatmap_on_rgb(img_np, heat, alpha=0.45)\n",
    "    heat_overlay = draw_yolo_boxes(heat_overlay, boxes_xyxy, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "    # (optional) show \"contrast enhanced\" heat for better viewing (doesn't change model)\n",
    "    heat_norm = normalize01(heat)\n",
    "    heat_norm_overlay = overlay_heatmap_on_rgb(img_np, heat_norm, alpha=0.45)\n",
    "    heat_norm_overlay = draw_yolo_boxes(heat_norm_overlay, boxes_xyxy, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "    plt.figure(figsize=(22, 14))\n",
    "\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plt.title(\"Input + YOLO boxes\")\n",
    "    plt.imshow(img_with_boxes); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 2)\n",
    "    plt.title(f\"Pred mask (score={score:.4f})\")\n",
    "    plt.imshow(predicted_mask, cmap=\"gray\"); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 3)\n",
    "    plt.title(\"GT mask\")\n",
    "    plt.imshow(gt_mask, cmap=\"gray\"); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 4)\n",
    "    plt.title(\"Pred overlay (red)\")\n",
    "    plt.imshow(pred_overlay); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 5)\n",
    "    plt.title(\"GT overlay (green)\")\n",
    "    plt.imshow(gt_overlay); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 6)\n",
    "    plt.title(\"GT+Pred overlay + boxes\")\n",
    "    plt.imshow(both_overlay); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 7)\n",
    "    plt.title(\"Prob heatmap (0..1)\")\n",
    "    plt.imshow(heat, cmap=\"jet\", vmin=0, vmax=1); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 8)\n",
    "    plt.title(\"Heatmap overlay + boxes\")\n",
    "    plt.imshow(heat_overlay); plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 3, 9)\n",
    "    plt.title(\"Heatmap normalized overlay (viz)\")\n",
    "    plt.imshow(heat_norm_overlay); plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # cleanup locals that can leak between iterations\n",
    "    if \"boxes_xyxy\" in locals():\n",
    "        del boxes_xyxy\n",
    "\n",
    "    # break_loop -= 1\n",
    "    # if break_loop == 0:\n",
    "    #     break\n",
    "\n",
    "    # # for crop in crops:\n",
    "    # #     plt.title(f\"mean_pixel: {np.mean(np.asarray(crop))}\")\n",
    "    # #     plt.imshow(crop)\n",
    "    # #     plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b1e60cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46814029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
