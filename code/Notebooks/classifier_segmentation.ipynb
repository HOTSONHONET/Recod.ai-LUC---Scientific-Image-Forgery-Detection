{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f948ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hotson/kaggle_work/recodai-luc-scientific-image-forgery-detection/code\n"
     ]
    }
   ],
   "source": [
    "%cd \"/home/hotson/kaggle_work/recodai-luc-scientific-image-forgery-detection/code\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df5af6",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fade4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import cv2  # type: ignore\n",
    "except Exception:  # pragma: no cover - optional dependency\n",
    "    cv2 = None\n",
    "\n",
    "from utils import evaluate_single_image, rle_encode, score as competition_score\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from dinov2_uperhead import DinoV2_UPerNet\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7549aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_case_id(raw) -> int | str:\n",
    "    if torch.is_tensor(raw):\n",
    "        raw = raw.item()\n",
    "    return int(raw) if isinstance(raw, (np.integer, int)) else str(raw)\n",
    "\n",
    "\n",
    "def enhanced_adaptive_mask(prob: np.ndarray, alpha_grad=0.45):\n",
    "    prob = np.asarray(prob, dtype=np.float32)\n",
    "    if prob.ndim == 3:\n",
    "        prob = prob[..., 0]\n",
    "\n",
    "    gx = cv2.Sobel(prob, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(prob, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "    grad_norm = grad_mag / (grad_mag.max() + 1e-6)\n",
    "\n",
    "    enhanced = (1 - alpha_grad) * prob + alpha_grad * grad_norm\n",
    "    enhanced = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
    "\n",
    "    thr = float(np.mean(enhanced) + 0.3 * np.std(enhanced))\n",
    "    mask = (enhanced > thr).astype(np.uint8)\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    return mask, thr\n",
    "\n",
    "\n",
    "def finalize_mask(prob: np.ndarray, orig_size_wh: tuple[int, int]):\n",
    "    # orig_size_wh MUST be (W,H)\n",
    "    mask, thr = enhanced_adaptive_mask(prob)\n",
    "    w, h = orig_size_wh\n",
    "    mask = cv2.resize(mask, (int(w), int(h)), interpolation=cv2.INTER_NEAREST)\n",
    "    return mask, thr\n",
    "\n",
    "\n",
    "def apply_overlay(img_np: np.ndarray, mask01: np.ndarray, color=(255, 0, 0), alpha=0.5):\n",
    "    overlay = img_np.copy()\n",
    "    mask_bool = mask01.astype(bool)\n",
    "    overlay[mask_bool] = (\n",
    "        alpha * np.array(color, dtype=np.float32)\n",
    "        + (1 - alpha) * overlay[mask_bool].astype(np.float32)\n",
    "    ).astype(np.uint8)\n",
    "    return overlay\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, case_ids, orig_sizes, mask_paths, image_paths, labels = zip(*batch)\n",
    "    images = default_collate(images)\n",
    "    return images, list(case_ids), list(orig_sizes), list(mask_paths), list(image_paths), list(labels)\n",
    "\n",
    "\n",
    "def infer_img_size_from_state(state_dict: dict, fallback: int) -> int:\n",
    "    pos_embed = state_dict.get(\"backbone.pos_embed\")\n",
    "    patch_weight = state_dict.get(\"backbone.patch_embed.proj.weight\")\n",
    "    if pos_embed is None or patch_weight is None:\n",
    "        return fallback\n",
    "\n",
    "    tokens = pos_embed.shape[1]\n",
    "    grid_tokens = tokens - 1\n",
    "    grid = int(math.sqrt(grid_tokens))\n",
    "    if grid * grid != grid_tokens:\n",
    "        return fallback\n",
    "\n",
    "    patch = int(patch_weight.shape[-1])\n",
    "    return grid * patch\n",
    "\n",
    "\n",
    "def create_collage(\n",
    "    image_path: str,\n",
    "    pred_bin: np.ndarray,\n",
    "    case_id: str,\n",
    "    score: float,\n",
    "    out_dir: Path,\n",
    "    gt_label: str,\n",
    "):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        orig_img = Image.open(f).convert(\"RGB\")\n",
    "    orig_np = np.array(orig_img)\n",
    "    vis_w, vis_h = orig_img.size  # (W,H)\n",
    "\n",
    "    if pred_bin.shape[:2] != (vis_h, vis_w):\n",
    "        pred_bin_vis = cv2.resize(pred_bin, (vis_w, vis_h), interpolation=cv2.INTER_NEAREST)\n",
    "    else:\n",
    "        pred_bin_vis = pred_bin\n",
    "\n",
    "    gt_mask = load_gt_mask_from_image_path(image_path = image_path, w = vis_w, h = vis_h)\n",
    "\n",
    "    if gt_mask.shape[:2] != (vis_h, vis_w):\n",
    "        gt_mask_vis = cv2.resize(gt_mask, (vis_w, vis_h), interpolation=cv2.INTER_NEAREST)\n",
    "    else:\n",
    "        gt_mask_vis = gt_mask\n",
    "\n",
    "    pred_mask_rgb = (pred_bin_vis[..., None] * 255).repeat(3, axis=2).astype(np.uint8)\n",
    "    gt_mask_rgb = (gt_mask_vis[..., None] * 255).repeat(3, axis=2).astype(np.uint8)\n",
    "\n",
    "    pred_overlay = apply_overlay(orig_np, pred_bin_vis, color=(255, 0, 0))\n",
    "    gt_overlay = apply_overlay(orig_np, gt_mask_vis, color=(0, 255, 0))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(18, 4))\n",
    "    titles = [f\"Input_{case_id}\", \"Pred mask\", \"GT mask\", \"Pred overlay\", \"GT overlay\"]\n",
    "    imgs = [orig_np, pred_mask_rgb, gt_mask_rgb, pred_overlay, gt_overlay]\n",
    "    for ax, img, title in zip(axes, imgs, titles):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    score_str = f\"{score:.3f}\".replace(\".\", \"pt\")\n",
    "    save_path = out_dir / f\"{gt_label}_{case_id}_{score_str}.png\"\n",
    "    plt.savefig(save_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def load_gt_mask_from_image_path(image_path: str, w: int, h: int) -> np.ndarray:\n",
    "    mask_path = (\n",
    "        image_path\n",
    "        .replace(\"train_images\", \"train_masks\")\n",
    "        .replace(\"supplemental_images\", \"supplemental_masks\")\n",
    "        .replace(\"/forged\", \"\")\n",
    "        .replace(\".png\", \".npy\")\n",
    "    )\n",
    "    if not Path(mask_path).exists():\n",
    "        return np.zeros(shape = (h, w), dtype = np.uint8)\n",
    "    \n",
    "    arr = np.load(mask_path, allow_pickle=True)\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr.max(axis=0)\n",
    "    gt_mask = (arr > 0).astype(np.uint8)\n",
    "    if gt_mask.shape[:2] != (h, w):\n",
    "        gt_mask = cv2.resize(gt_mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "    return gt_mask\n",
    "\n",
    "\n",
    "def save_hist(values, title, out_path: Path, bins=50):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(values, bins=bins)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33bf5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel:\n",
    "    def __init__(self, model_id: str, device: torch.device):\n",
    "        self.encoder = AutoModel.from_pretrained(model_id).eval().to(device)\n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode_from_pixel_values(self, pixel_values: torch.Tensor):\n",
    "        out = self.encoder(pixel_values=pixel_values)\n",
    "        cls = out.last_hidden_state[:, 0, :]  # [B, D]\n",
    "        return cls.float().cpu().numpy()\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, img_size: int, processor):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_size = int(img_size)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        case_id = str(row[\"case_id\"])\n",
    "        image_path = str(row[\"image_path\"])\n",
    "        label = int(row.get(\"label\", 0))\n",
    "\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "        orig_size = img.size  # (W,H)\n",
    "\n",
    "        img_rs = transforms.functional.resize(img, (self.img_size, self.img_size))\n",
    "        processed = self.processor(\n",
    "            images=img_rs,\n",
    "            return_tensors=\"pt\",\n",
    "            do_resize=False,\n",
    "            do_center_crop=False,\n",
    "            do_normalize=True,\n",
    "            do_rescale=True,\n",
    "        )\n",
    "        img_t = processed[\"pixel_values\"].squeeze(0)  # [C,H,W] torch tensor\n",
    "\n",
    "        return img_t, case_id, orig_size, image_path, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, case_ids, orig_sizes, image_paths, labels = zip(*batch)\n",
    "    images = default_collate(images)  # [B,C,H,W]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return images, list(case_ids), list(orig_sizes), list(image_paths), labels\n",
    "\n",
    "def remove_small_components(mask01: np.ndarray, min_area: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    mask01: uint8/bool (H,W) with values {0,1}\n",
    "    min_area: remove connected components smaller than this many pixels\n",
    "    \"\"\"\n",
    "    if min_area is None or min_area <= 0:\n",
    "        return (mask01 > 0).astype(np.uint8)\n",
    "\n",
    "    m = (mask01 > 0).astype(np.uint8)\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(m, connectivity=8)\n",
    "\n",
    "    out = np.zeros_like(m, dtype=np.uint8)\n",
    "    for lab in range(1, num_labels):\n",
    "        if stats[lab, cv2.CC_STAT_AREA] >= min_area:\n",
    "            out[labels == lab] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962277b",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698861c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    csv_path = \"../analysis/area_splits/val_fold0.csv\"\n",
    "    weights_path = \"../exps/20260110_131204/vit_base_patch14_dinov2.lvd142m_fold0.pt\"\n",
    "    arch: str = \"dinov2_uperhead\"\n",
    "    dinov2_id: str = \"facebook/dinov2-base\"\n",
    "    model_name: str = \"vit_base_patch14_dinov2.lvd142m\"\n",
    "    img_size: int = 532\n",
    "    use_hf_processor: bool = True\n",
    "    outdir: Path = \"../analysis/preds_nposw\"\n",
    "    save_collages: bool = True\n",
    "    logistic_regression_model: str = \"../exps/classifiers/20260113_074223/models/logreg/model.pkl\"\n",
    "    svc_model: str = \"../exps/classifiers/20260113_074223/models/linear_svm_calibrated/model.pkl\"\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_seg_params: str = \"../analysis/preds_nposw_dinov2_uperhead/analysis/run_metadata.json\"\n",
    "    best_svc_params: str = \"../exps/classifiers/20260113_074223/models/linear_svm_calibrated/metrics.json\"\n",
    "    best_lgr_params: str = \"../exps/classifiers/20260113_074223/models/logreg/metrics.json\"\n",
    "\n",
    "if args.img_size % 14 != 0:\n",
    "    raise ValueError(f\"{args.arch} requires img_size divisible by 14 (Dinov2 patch size).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded Segmentation model\n",
      "[INFO] Loaded classifiers\n",
      "[INFO] Loaded classifiers\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Dataset / loader\n",
    "# -------------------------\n",
    "\n",
    "df = pd.read_csv(args.csv_path)\n",
    "\n",
    "hf_processor = AutoImageProcessor.from_pretrained(args.dinov2_id)\n",
    "dataset = InferenceDataset(df, img_size=args.img_size, processor=hf_processor)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Models\n",
    "# -------------------------\n",
    "model = DinoV2_UPerNet(dinov2_id=args.dinov2_id, num_classes=1).to(args.device)\n",
    "state = torch.load(args.weights_path, map_location=args.device)\n",
    "model_state = state[\"model_state\"]\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "print(\"[INFO] Loaded Segmentation model\")\n",
    "\n",
    "clf_logreg = joblib.load(args.logistic_regression_model)\n",
    "clf_svc = joblib.load(args.svc_model)\n",
    "print(\"[INFO] Loaded classifiers\")\n",
    "\n",
    "embedder = EmbeddingModel(args.dinov2_id, args.device)\n",
    "print(\"[INFO] Loaded classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e6e3d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 513/513 [00:57<00:00,  8.89it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(args.best_seg_params, \"r\") as f:\n",
    "    best_seg_params = json.load(f)\n",
    "\n",
    "best_seg_params = best_seg_params[\"best_params\"]\n",
    "\n",
    "with open(args.best_lgr_params, \"r\") as f:\n",
    "    best_clf_lg_params = json.load(f)\n",
    "\n",
    "with open(args.best_svc_params, \"r\") as f:\n",
    "    best_clf_svc_params = json.load(f)\n",
    "\n",
    "predictions = []\n",
    "solution_rows = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, case_ids, orig_sizes, image_paths, labels in tqdm(loader, desc=\"Predicting\"):\n",
    "        images = images.to(args.device, non_blocking=True)\n",
    "\n",
    "        emb = embedder.encode_from_pixel_values(images)           # (B,D) numpy\n",
    "        proba_lr = clf_logreg.predict_proba(emb)[:, 1]            # (B,)\n",
    "        proba_svc = clf_svc.predict_proba(emb)[:, 1]              # (B,)\n",
    "\n",
    "        out = model(images)\n",
    "        logits = out if torch.is_tensor(out) else out[0]\n",
    "        probs = torch.sigmoid(logits).float().cpu().numpy()       # (B,1,S_h,S_w)\n",
    "\n",
    "        for i, case_id in enumerate(case_ids):\n",
    "            cid = str(normalize_case_id(case_id))\n",
    "            orig_w, orig_h = orig_sizes[i]\n",
    "            prob = probs[i, 0]                                    # (S_h,S_w)\n",
    "\n",
    "            mask_full, thr = finalize_mask(prob, (int(orig_w), int(orig_h)))  # (H,W)\n",
    "            gt_mask = load_gt_mask_from_image_path(image_paths[i], int(orig_w), int(orig_h))\n",
    "            gt_label = \"authentic\" if int(labels[i]) == 0 else \"forged\"\n",
    "            shape_str = json.dumps([int(orig_h), int(orig_w)])\n",
    "\n",
    "            # binarize + cc filter\n",
    "            pred_bin = (mask_full > 0).astype(np.uint8)\n",
    "            pred_bin = remove_small_components(pred_bin, int(best_seg_params.get(\"min_cc_area\", 0))).astype(np.uint8)\n",
    "\n",
    "            # area + mean_inside (align to prob shape)\n",
    "            area = int(pred_bin.sum())\n",
    "            if area > 0:\n",
    "                S_h, S_w = prob.shape\n",
    "                mask_small = cv2.resize(pred_bin, (S_w, S_h), interpolation=cv2.INTER_NEAREST)\n",
    "                mean_inside = float(prob[mask_small == 1].mean()) if (mask_small == 1).any() else 0.0\n",
    "            else:\n",
    "                mean_inside = 0.0\n",
    "\n",
    "            # seg gating label\n",
    "            a_thr = int(best_seg_params[\"area_thres\"])\n",
    "            m_thr = float(best_seg_params[\"mean_thres\"])\n",
    "            pred_mask_thres = \"forged\" if (area >= a_thr and mean_inside >= m_thr) else \"authentic\"\n",
    "\n",
    "            # rle (only if forged + non-empty)\n",
    "            if pred_mask_thres == \"forged\" and area > 0:\n",
    "                rle_str = rle_encode([pred_bin])\n",
    "            else:\n",
    "                rle_str = \"authentic\"\n",
    "\n",
    "            predictions.append(dict(\n",
    "                case_id=cid,\n",
    "                image_path=image_paths[i],\n",
    "                orig_width=int(orig_w),\n",
    "                orig_height=int(orig_h),\n",
    "\n",
    "                prob=prob.astype(np.float32),\n",
    "                pred_mask=pred_bin,           # store final filtered mask (better than raw mask_full)\n",
    "                thr=float(thr),\n",
    "\n",
    "                gt_mask=gt_mask.astype(np.uint8),\n",
    "                gt_label=gt_label,\n",
    "                shape_str=shape_str,\n",
    "\n",
    "                proba_lr=float(proba_lr[i]),\n",
    "                proba_svc=float(proba_svc[i]),\n",
    "                embedding=emb[i].astype(np.float32),\n",
    "\n",
    "                pred_lr=\"forged\" if float(proba_lr[i]) >= float(best_clf_lg_params[\"threshold_best_f1\"]) else \"authentic\",\n",
    "                pred_svc=\"forged\" if float(proba_svc[i]) >= float(best_clf_svc_params[\"threshold_best_f1\"]) else \"authentic\",\n",
    "                pred_mask_thres=pred_mask_thres,\n",
    "\n",
    "                mask_area=area,\n",
    "                mask_mean_inside=float(mean_inside),\n",
    "\n",
    "                rle_encode_str=rle_str,\n",
    "            ))\n",
    "\n",
    "            solution_rows.append(dict(\n",
    "                case_id=cid,\n",
    "                annotation=\"authentic\" if gt_label == \"authentic\" else rle_encode([gt_mask.astype(np.uint8)]),\n",
    "                shape=shape_str,\n",
    "            ))\n",
    "\n",
    "solution_df = pd.DataFrame(solution_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505ae60",
   "metadata": {},
   "source": [
    "### Competition scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8dbf8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          logic    score\n",
      "        lgr_and_pred_mask_thres 0.540774\n",
      " lgr_or_svc_and_pred_mask_thres 0.540774\n",
      "lgr_and_svc_and_pred_mask_thres 0.538667\n",
      "        svc_and_pred_mask_thres 0.538667\n",
      "         svc_or_pred_mask_thres 0.532601\n",
      "         lgr_or_pred_mask_thres 0.532601\n",
      "  lgr_or_svc_or_pred_mask_thres 0.532601\n",
      " lgr_and_svc_or_pred_mask_thres 0.532601\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_submission_from_logic(predictions, decide_fn):\n",
    "    rows = []\n",
    "    for p in predictions:\n",
    "        is_forged = bool(decide_fn(p))\n",
    "        if is_forged:\n",
    "            ann = p[\"rle_encode_str\"]  # should already be \"authentic\" if empty\n",
    "            # safety: don't allow forged label with empty rle\n",
    "            if ann == \"authentic\":\n",
    "                ann = \"authentic\"\n",
    "        else:\n",
    "            ann = \"authentic\"\n",
    "        rows.append({\"case_id\": str(p[\"case_id\"]), \"annotation\": ann})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def score_logic(name, predictions, solution_df, decide_fn):\n",
    "    submission_df = make_submission_from_logic(predictions, decide_fn)\n",
    "    s = competition_score(solution=solution_df, submission=submission_df, row_id_column_name=\"case_id\")\n",
    "    return name, float(s)\n",
    "\n",
    "# helpers: convert label strings to bool\n",
    "def is_lr(p):  return p[\"pred_lr\"] == \"forged\"\n",
    "def is_svc(p): return p[\"pred_svc\"] == \"forged\"\n",
    "def is_mask(p):return p[\"pred_mask_thres\"] == \"forged\"\n",
    "\n",
    "logics = [\n",
    "    (\"lgr_and_pred_mask_thres\", lambda p: is_lr(p) and is_mask(p)),\n",
    "    (\"lgr_or_pred_mask_thres\",  lambda p: is_lr(p) or  is_mask(p)),\n",
    "\n",
    "    (\"svc_and_pred_mask_thres\", lambda p: is_svc(p) and is_mask(p)),\n",
    "    (\"svc_or_pred_mask_thres\",  lambda p: is_svc(p) or  is_mask(p)),\n",
    "\n",
    "    (\"lgr_and_svc_and_pred_mask_thres\", lambda p: is_lr(p) and is_svc(p) and is_mask(p)),\n",
    "    (\"lgr_or_svc_or_pred_mask_thres\",   lambda p: is_lr(p) or  is_svc(p) or  is_mask(p)),\n",
    "\n",
    "    # mixed ones (often useful)\n",
    "    (\"lgr_and_svc_or_pred_mask_thres\",  lambda p: (is_lr(p) and is_svc(p)) or is_mask(p)),\n",
    "    (\"lgr_or_svc_and_pred_mask_thres\",  lambda p: (is_lr(p) or  is_svc(p)) and is_mask(p)),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, fn in logics:\n",
    "    results.append(score_logic(name, predictions, solution_df, fn))\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"logic\", \"score\"]).sort_values(\"score\", ascending=False)\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0475b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
